{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "requests_dir = '../data/input/requests'\n",
    "response_dir = '../data/input/responses'\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append('../utils')\n",
    "import helpers as h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining all routes in a single df.\n",
    "We'll output a single dataframe that has all route requests read and parsed into a single df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_request(route_id, ymd, idx_file):\n",
    "    \"\"\"\n",
    "    Gepaste docstring in het goede formaat.\n",
    "    Als je dit in het goede formaat doet kan je meteen documentatie maken\n",
    "    https://realpython.com/python-project-documentation-with-mkdocs/\n",
    "\n",
    "    Functie van Tim\n",
    "    \"\"\"\n",
    "    \n",
    "    folder_requests = os.path.join('..', 'data', 'input', 'requests', f\"{route_id}-{ymd}\")\n",
    "    if not os.path.exists(folder_requests):\n",
    "        return None\n",
    "\n",
    "    file_request = os.listdir(folder_requests)[idx_file]\n",
    "    file_path_request = os.path.join(folder_requests, file_request)\n",
    "    print(file_path_request)\n",
    "    with open(file_path_request, 'r') as f:\n",
    "        request = json.load(f)\n",
    "    print('OK')\n",
    "    rows = list()\n",
    "    for task in request['tasks']:\n",
    "        # TODO: Dit kan efficienter met een specifieke methode (pd.explode, json to dataframe zaken)\n",
    "        if task['id'] == 'E1':\n",
    "            continue ## TODO: Also retain this task!\n",
    "        row = {'id' : int(task['id']),\n",
    "                    'lat' : task['address']['latitude'],\n",
    "                    'long' : task['address']['longitude'],\n",
    "                    'start_time' : task['timeWindow']['from'],\n",
    "                    'end_time' : task['timeWindow']['till']}\n",
    "        rows.append(row)\n",
    "\n",
    "    return pd.DataFrame(rows).sort_values(by = 'id')\n",
    "def get_route_dataframe(route_id, ymd, idx_file): \n",
    "    \"\"\"\n",
    "        Simple one linter that uses read_reques and sort_request to\n",
    "        get the route dataframe from the JSON file, can be used as\n",
    "        input for other functions. \n",
    "    \"\"\"\n",
    "    df_request = read_request(route_id, ymd, idx_file)\n",
    "    #df_request = sort_request(df_request, route_id, ymd, idx_file)\n",
    "    return df_request\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3726/3726 [05:28<00:00, 11.35it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def json_request_to_df(path): \n",
    "    \"\"\"\n",
    "        variation on Tim's function 'read_request', we'll not let a funciton decide\n",
    "        what index file (last integer iin the filename) to read. in stead we do this\n",
    "        in the df itself applying filters where needed. Gives us more control in case\n",
    "        a json response for a hardcoded idx in read_requst is invalid. \n",
    "\n",
    "        ARGUMENTS: \n",
    "            path = str = Fully qualified path to a json file\n",
    "\n",
    "        RETURNS: \n",
    "            pandas dataframe\n",
    "    \"\"\"\n",
    "    with open(path, 'r') as f:\n",
    "        request = json.load(f)\n",
    "    rows = list()\n",
    "    #meta: \n",
    "    file_uuid = request['id']\n",
    "    configurationName = request['configurationName']\n",
    "    for task in request['tasks']:\n",
    "        # TODO: Dit kan efficienter met een specifieke methode (pd.explode, json to dataframe zaken)\n",
    "        if task['id'] == 'E1':\n",
    "            continue ## TODO: Also retain this task!\n",
    "        row = { \n",
    "                'file_uuid' : file_uuid,\n",
    "                'configurationName' : configurationName,\n",
    "                'id' : int(task['id']),\n",
    "                'lat' : task['address']['latitude'],\n",
    "                'long' : task['address']['longitude'],\n",
    "                'start_time' : task['timeWindow']['from'],\n",
    "                'end_time' : task['timeWindow']['till']\n",
    "                }\n",
    "        rows.append(row)\n",
    "\n",
    "    return pd.DataFrame(rows).sort_values(by = 'id')\n",
    "\n",
    "#reading requests: \n",
    "internal_id = 1     #using internal_id we can quikly comminicate with each other what precise file we want to look at for debugging/app-feature design. \n",
    "all_content = []    # the final dataframe (build once all data is read)\n",
    "for dir in tqdm(os.listdir(requests_dir)):\n",
    "    if dir.endswith(\".txt\"):\n",
    "        continue\n",
    "    route_id = dir.split('-')[0]\n",
    "    route_date = h.routedatestring_to_date(dir.split('-')[1])\n",
    "    contents = os.listdir(os.path.join(requests_dir, dir))\n",
    "    for file in contents:\n",
    "        if file.endswith('.json'): \n",
    "            fn = file.rstrip('.json').split('-')\n",
    "            idblock_1 = fn[2]\n",
    "            idblock_2 = fn[3]\n",
    "            idblock_3 = fn[4]\n",
    "            fq_path = os.path.join(requests_dir, dir, file)\n",
    "            content_of_file = json_request_to_df(fq_path)\n",
    "            #enabling us to identify rows belong to a specific file on the drive. \n",
    "            content_of_file['dir'] = dir\n",
    "            content_of_file['route_id'] = route_id\n",
    "            content_of_file['route_date'] = route_date\n",
    "            content_of_file['idblock_1'] = idblock_1\n",
    "            content_of_file['idblock_2'] = idblock_2\n",
    "            content_of_file['idblock_3'] = idblock_3\n",
    "            content_of_file['internal_id'] = internal_id\n",
    "            internal_id+=1\n",
    "            all_content.append(content_of_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_requests = pd.concat(all_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('../data/intermediate', exist_ok=True)\n",
    "df_requests.to_csv('../data/intermediate/requests.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_learning_driver_preferences",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
